\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}

\title{Identification of Songbird Species in Field Recordings
%  \footnote{10-701 Machine Learning Final Project Proposal}
}


\author{
Hsiao-Yu Tung \\
%Carnegie Mellon University\\
%\texttt{htung@andrew} \\
\texttt{htung@andrew.cmu.edu} \\
htung \\
\And
De-An Huang \\
%Carnegie Mellon University\\
%\texttt{deanh@andrew} \\
\texttt{deanh@andrew.cmu.edu} \\
deanh \\
\And
Xiao-Feng Xie \\
%Carnegie Mellon University\\
%\texttt{xfxie@cs} \\
\texttt{xfxie@cs.cmu.edu} \\
xfxie \\
\And
Yurui Zhou\\
%\texttt{yuruiz@andrew}\\
\texttt{yuruiz@andrew.cmu.edu}\\
yuruiz \\
\And
Joseph Russino\\
%\texttt{yuruiz@andrew}\\
\texttt{jrussino@rec.ri.cmu.edu}\\
jrussino \\
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

% \begin{abstract}
% \end{abstract}

\section{Introduction}
Given the documented declines in many migrant songbird populations, there is a pressing need to gain a more complete understanding of all aspects of migration patterns.
%Particularly, flight calling behavior is one of the least studied areas of migration biology.
During migratory periods, many species of songbirds use flight calls, which are species-specific and are distinct from other vocalizations. Therefore, flight calls information can be used to determine the relative abundance of species and is important to understand long-term population trends. Identification of bird species from continuous audio recordings has been a hot topic in recent conference competitions.\footnote{\scriptsize ICML 2013: \href{http://www.kaggle.com/c/the-icml-2013-bird-challenge}{The Bird Challenge}; NIPS 2013: \href{http://www.kaggle.com/c/multilabel-bird-species-classification-nips2013}{
Multi-label Bird Species Classification}; MLSP 2013: \href{http://www.kaggle.com/c/mlsp-2013-birds}{Bird Classification Challenge}}.

%\footnote{\href{http://www.kaggle.com/c/the-icml-2013-bird-challenge}{ICML 2013: The Bird Challenge}}$^,$\footnote{\href{http://www.kaggle.com/c/multilabel-bird-species-classification-nips2013}{
%NIPS 2013: Multi-label Bird Species Classification}}$^,$\footnote{\href{http://www.kaggle.com/c/mlsp-2013-birds}{MLSP 2013: Bird Classification Challenge}}.

{\bf Data Set} Large amounts of audio data (about 20 terabytes) for bird calls have been collected. The data contain flight calls from approximately 20-30 species of songbirds, examples of other background noises, and long audio files that contain flight calls (some of them might be too faint to identify them to species) and other background sounds. The software developed can be tested using long audio files where all the flight calls of songbirds have been detected, and with manual identification by Amy Tegeler, an Avian Ecologist from the Carnegie Museum of Natural History.

%Flight calls vary in structure; some species have flight calls that are very similar while other species flight calls are very unique. For example, calls may differ in a variety of acoustic traits including whether they are pure or modulated tones, rise or fall during the call, and/or contain a single band or include harmonics. Warbler flight calls are commonly split into 6 flight call types based on similarity of structure: buzzy, single banded upsweep, double banded upsweep, double banded upsweep, down sweep, zeep, and irregular.

{\bf Project Ideas \& Software} In this project, we will focus on two critical aspects of this problem. First, we will work on segmenting flight call vocalizations within long audio files that contain other types of sounds. Second, given labeled segments of bird flight calls, we will explore possible algorithms to extract useful features and classify the corresponding songbird species automatically.

%\section{Plan of Action}

We plan to start from some state-of-the-art algorithms \cite{briggs2013instance,Lasseck13,Massaron13,stattnersong13}, adapt components to the data we have, and finally develop a scalable, integrated software tool.
The audio data are first preprocessed into spectrograms using Fourier transformation or existing sound analysis software (e.g., \href{http://www.birds.cornell.edu/brp/raven/}{Raven}). The spectrograms are further cleaned by applying background noise reduction and image processing techniques. Afterward, connected pixels (acoustic patterns) in the spectrograms are labeled into rectangle segments.  We then extract and select features from different sources, e.g., file statistics, segment statistics and probabilistics, and mel-frequency cepstral coefficients, etc. Finally, the classification can then be done using multiple algorithms, e.g., decision trees, support vector machines, and multi-instance multi-label learning algorithms, as well as some ensemble methods to further improve the overall performance, based on existing libraries (e.g., \href{http://scikit-learn.org}{scikit-learn}). %Hierarchical classification techniques might also be considered to utilize the domain-specific knowledge structure in flight calls across different species. 

{\bf Work Division} Yurui Zhou will work on preprocessing and segmentation;Joseph Russino will tackle feature extraction and selection; Hsiao-Yu Tung and De-An Huang will focus on classification algorithms; and Xiao-Feng Xie will work on ensemble learning methods. Each group member will do assistance work on at least one task of others to gain experience and improve on the overall system.  

{\bf Midterm Milestone} Develop an initial workable software version and perform basic tests based on indoor voice data, after selecting suitable algorithm components that might work scalable.

%%We will be collaborating with Amy Tegeler, the Avian Ecologist and Bioacoustics Lab Manager at Powdermill Nature Reserve, the field station for the Carnegie Museum of Natural History.
{\bf Project Outline} The software developed for this project will be used by the Carnegie Museum of Natural History, and possibly shared with other land managers, researchers, and educators to enhance the use of flight calls as a method to study the populations of migratory songbirds. %The software is scalable so that users could train it to identify flight calls from additional species and to exclude other types of background noise.

\section{Features}
\subsection{Mel-Frequency Cepstrum Coefficients }
While flight calls recognition is a new application, audio recognition is a well developed area in signal processing. We will build features based on  mel-frequency cepstrum coefficients (MFCCs), which are commonly used as features in speech recognition systems. A temporal signal is first transformed into a series of frames where each frame consists of 13 MFCCs. Each frame represents a duration of 12ms. The step size is 4ms. We also include the fist and second derivatives of MFCCs, which results in a 39 (13$\times$3) dimensional vector for each frame.

\subsection{Bag-of-Words Model over MFCCs}
\label{sec:bow}

In contrast to \cite{Dufour_NIPSW13}, which assumes that the number of frames is fixed for all audio segments to classify, we make no assumption on the length of the audio segment, since the length of flight calls might variate. In this case, we want a feature that is temporally scale invariant. Intuitively, even when a flight call is temporally scaled (extended or shorten), it should still be classified as the flight call of the same species. We leverage the progress in image classification and applied the bag-of-words (BoW) model \cite{Li_CVPR05} over our MFCCs. By treating audio features (MFCCS in our case) as `words', each audio segment is represented by a sparse vector of occurrence counts of words in BoW model; that is, a sparse histogram over the vocabulary.

We learn the vocabulary, also called the codebook, by performing k-means clustering over sampled training MFCCs. Codewords are then defined as the centers of the learned clusters. In test time, we extract MFCCs from the test audio segment and quantize the 39 dimensional MFCCs to a learned codeword. The audio segment is represented by a $K$ dimensional histogram over the codeword, where $K$ is the size of the codebook. 

One limitation of BoW model on audio segment is that the temporal information are lost in the model. However, as shown in the experiments, BoW is able to achieve satisfactory classification result on single-label single-instance case. We are considering to build higher order N-gram model on the learned vocabulary to capture the temporal information.



\section{Classifiers}
We consider several classifiers/regressors.

\textbf{Nearest Neighbor (NN).} For each testing data, the NN classifier finds the nearest training data point and transfer the corresponding label. The NN classifier directly reflect the effect of our features and is used as baseline. Depends on the features, different distance metric should be used. We will compare the performance of euclidean and $\chi^2$ distance on the BoW feature in the experiments.

\textbf{Support Vector Machine (SVM).} The most common approach for multilabel classification is to use an ensemble of binary classifiers, where each classifier predicts if an instance belongs to
one specific class or not. SVMs trained in a pairwise fashion has obtained state-of-the-art results on standard multi-label benchmark datasets \cite{Mencia_NIPSW13}. Furthermore, we will be able to integrate different kernels to improve the performance using the SVM. For example, the $\chi^2$ kernel will have a better performance for histogram than the linear kernel. We also consider support vector regression to produce soft output for ensemble learning.

%textbf{Support Vector Regression (SVR).} We use SVR to produce a soft output version of SVM

\textbf{Random Forest.} Random forests has been widely used for multilabel classification \cite{Lasseck13, chennovel13, Stowell_NIPSW13, Zhang_SDM2010}.
Random Forest is operated by constructing decision tree structure by the training examples. One of the popular algorithm is tree bagging, in which the training process includes repeatedly selecting a bootstrap sample of the training set and  fitting the trees to them. After the training process, the label decision is made either on the majority of the votes or a weighted combination from all individual tree.

%\textbf{Naive Bayes.} 

\textbf{Logistic Regression.} Ensemble of logistic regression has been used for mutlilabel bird song classification \cite{Massaron13} because of its simplicity. We also consider logistic regression as the baseline for soft output.



\section{Experiments}
We first evaluate our system on single-label data to see if the flight calls are separable using our method.

\textbf{Data.} 
We use the flight calls of songbirds manually segmented and labelled by Amy Tegeler, an Avian Ecologist from the Carnegie Museum of Natural History, to evaluate the performance of our system on indoor flight calls classification. We used the data from year 2008 to 2013. The total number of species is 32. But only 11 species has more than 100 data. Therefore, the experiment is performed on those 11 species, and 100 data points are randomly sampled from each species. The 100 data points are randomly partitioned into 20 testing data and 80 training data for each species.


\textbf{Segmentation.}
Since the flight call segments are already manually identified, we do not perform segmentation in this experiment.

\textbf{Features.}
We use the BoW over MFCCs in Section \ref{sec:bow} as the features for this experiment. The size of the code book is 200, and the MFCCs consider the frequencies from 1500 Hz to 22000Hz.

\textbf{Classifiers}
Before beginning with the training process, we first examine the property of the data. We can see that most of the value in the original data is zero. After taking the log value of the data, we can find that a small group of the data is separated from the others. In some of the dimension, this small contains only a number of specific species of birds, which might be helpful in the classification.
\begin{figure}[ht!]
    \centering
    {(a)\includegraphics[width=0.45\linewidth]{../Figure/Train_features}
    (b)\includegraphics[width=0.45\linewidth]{../Figure/Train_features_log}}
    \caption{(a) is the histogram of second feature. Most of the values are close to zero. (b) is the histogram of the log value of the original data.}
    \label{fig:hist}
\end{figure}


We compare the results using nearest neighbor, support vector machine, random forest and naive bayes classifier.


\begin{center}
\begin{small}
\captionof{table}{\small Accuracy of different classifier}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
    KNN & distance      &accuracy   &SVM    & kernel type       &accuracy\\
\hline
        & chi-square    &62.27      &       &chi-square kernel  &72.73\\
\hline
        & euclidean     &54.09      &       & RBF               &70\\
\hline
RandomForest &         & 7.27           &       & linear            &67.7273\\
\hline
Naive Bayes  & kernel densoty  & 15.91           &       & polynomial        &69.0909\\
\hline
        &               &           &       & Sigmoid           &70.9091\\
\hline
\end{tabular}
\end{small}
\end{center}

We can see from our results that kernel SVM has better performance than the other method. First we show the parameter selection in using RBF kernel. Figure \ref{fig:RBF} shows the accuracy to the penalty term $C$ and the parameter $\gamma$. The parameter we selected are $\gamma = 15$ and $C = 4000$.

\begin{figure}[ht!]
    \centering
    {(a)\includegraphics[width=0.45\linewidth]{../Figure/RBF_cost_accuracy}
    (b)\includegraphics[width=0.45\linewidth]{../Figure/RBF_gamma_accuracy}}
    \caption{(a) Accuracy to penalty term c. (b) Accuracy to parameter $\gamma$. }
    \label{fig:RBF}
\end{figure}

In considering that original feature distribution is not a Gaussian distribution, for $x_i,j$ representing the $j^{th}$ feature in the object $i$, we first use a log transformation such that $x_{i,j} = log(x_{i,j} + 0.0001)$ to make the feature distribution more like a combination of Gaussian distribution (see \ref{fig:hist}(b)). The operation leads to a 1.27 improvement in the accuracy after parameter selection process.


\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.45\linewidth]{../Figure/RBF_cost_accuracy_log}
     \centering
    \caption{Accuracy to penalty C after log transformation on the original feature.}
\end{figure}

Next, we show the results for applying SVM with polynomial kernel. Figure \ref{fig:poly} shows that the performance of accuracy to penalty C is similar to RBF kernel and the optimal value of this parameter is 16000. Besides, according to the experiment results, the optimal degree for the data is around 2. The reason might due to small data size that we use recently so that increasing model complexity will lead to overfitting problem. So we focus on simple model for recent data.  
 
\begin{figure}[ht!]
    \centering
    {(a)\includegraphics[width=0.45\linewidth]{../Figure/Poly_cost_accuracy}
    (b)\includegraphics[width=0.45\linewidth]{../Figure/Poly_degree_accuracy}}
    \caption{(a) Accuracy to penalty term c. (b) Accuracy to parameter degree d}
    \label{fig:poly}
\end{figure}

The reason why random forest and naive bayes failed is that the training example for each species is now limited to 80. From the predicted classification labels from the results of random forest, we found that the identities in some of the class are all misclassfied into another class, which means that the tree is ill-trained and biased such that many cases will be made to the same decision. 



\bibliographystyle{abbrv}
\bibliography{../bib/birds}

\end{document}
