\subsubsection{Bootstrap aggregating (bagging)}
Bootstrap aggregating, often abbreviated as bagging \cite{breiman1996bagging}, involves having each model in the ensemble vote with equal weight.

\subsubsection{Random forest}

Random forest \cite{breiman2001random}: operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes output by individual trees. 

\subsubsection{AdaBoost}



AdaBoost \cite{freund1997decision}, short for "Adaptive Boosting", in the sense that subsequent classifiers built are tweaked in favor of those instances misclassified by previous classifiers. 


\subsubsection{Bayesian model averaging}

Bayesian model averaging (BMA) \cite{hoeting1999bayesian}  is a pratical ensemble technique that seeks to approximate the Bayes Optimal Classifier by sampling hypotheses from the hypothesis space, and combining them using Bayes' law.